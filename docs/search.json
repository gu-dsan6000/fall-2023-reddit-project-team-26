[
  {
    "objectID": "business_questions.html",
    "href": "business_questions.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "Over the course of this project, we aim to answer different data science questions. The first few questions will be exploratory data analysis, which we have presented for you here. The next questions will be on NLP and machine learning, which will vary in complexity and in which part of the data set they are analyzing. We aim to answer these questions through multiple visual avenues, including plots, graphs, and charts, and aim to expose some interesting trends in collegiate basketball over the course of the 2021-2022 season.\n\n\nBusiness Goal 1: Determine how reddit activity ebbs and flows over the course of a collegiate basketball season. Construct visuals to aid in understanding how much reddit users post over the course of the 2022 season.\nTechnical Proposal: Group by date to determine the number of comments and submissions in the college basketball subreddit and visualize both of these time series plots. Compute the word count in each comment/submission and plot the average word count by day over the time period. Finally plot a heatmap comparing the count of comments on each day of week/hour of day combination to identify and weekly/daily cyclical trends.\nBusiness Goal 2: Explore how the subreddit page of the NCAA champion in 2022, the Kansas Jayhawks, varied over the course of the season. Identify any trends in post frequency or comment length that may correlate to on-the-court successes or failures.\nTechnical Proposal: Use trend analysis and count number of comments and comment lengths to determine excitement over the course of the CBB season. Correlate any major trends to outside data sets, including Jayhawks wins and losses or injuries of key players. Analyze any additional trends in activity over the course of the 2022 season to find any other additional results before entering into the NLP phase of the project.\nBusiness Goal 2.5: Explore how the subreddit page of the NCAA runner ups in 2022, the UNC Tarheels, varied over the course of the season. Identify any trends in post frequency or comment length that may correlate to on-the-court successes or failures.\nTechnical Proposal: Use trend analysis and count number of comments and comment lengths to determine excitement over the course of the CBB season. Correlate any major trends to outside data sets, including UNC wins and losses or major games. Analyze any additional trends in activity over the course of the 2022 season to find any other additional results before entering into the NLP phase of the project.\nBusiness Goal 3: Identify the teams that have the most engagement on the main college basketball subreddit.\nTechnical Proposal: Use grouping and sorting algorithms to find which college basketball teams are the most mentioned teams. Using key word searches we can identify mentions of these teams. Identify if these mentions ebb or flow over the course of the season.\n\n\n\nBusiness Goal 4: Rank CBB players in terms of popularity across subreddits. Look at which players have the most mentions overall and over time.\nTechnical Proposal: Use NLP techniques to identify which players are the most popular in collegiate basketball by analyzing how many times they are mentioned or are referred to in comments. Extract mentions of player names using NLP techniques and count frequency. Perform groupby commands to identify which player is the most popular in each month.\nBusiness Goal 5: Understand how player transfers in CBB affect fan engagement on relevant subreddits.\nTechnical Proposal: Identify which reddit posts are discussing transfers by extracting key words using regex. Perform a group by date to find number of discussions per day. Perform time series analysis by plotting discussions per day to determine when transfers are heavily discussed.\nBusiness Goal 6: Determine how collegiate fan bases react after big wins and big losses. Identify volatility over the course of the season, especially for teams we know reach the championship.\nTechnical Proposal: Identify fan sentiment for two days following a “big win” or a “big loss”. A big win could be some definition such as by beating a team by 20 points, and a big loss could be some definition such as losing to a team by more than 20 points. Analyze how fans of championship-caliber teams react to victory and defeat. Use NLP techniques to identify any rivalries or particularly important games to fanbases.\nBusiness Goal 7: Determine which teams are the most liked or most hated in college basketball.\nTechnical Proposal: Incorporate results of the EDA portion of most mentioned teams. Conduct NLP analysis to determine if these mentions are positive or negative. Expand analysis to surrounding comments and threads to understand which teams are generally viewed favorably or which are viewed negatively. Use external news sources to understand how fans view unlikely winners, such as “cinderella stories,” or losers, such as “upsets.”\n\n\n\nBusiness Goal 8: Predict which comments are more popular than others in the College Basketball subreddit.\nTechnical Proposal: Determine why certain comments are more popular than others in the College Basketball subreddit. Using Random Forest Regressor to identify if factors such as sentiment, time of post, date of post, comment length, activity of author, and whether or not the author has a team icon for their profile picture are relevant in determining how popular a post will be. Use a hyperparameter search to identify the best model.\nBusiness Goal 9: Build a model that predicts the results of Kansas games.\nTechnical Proposal: Use sentiment analysis and comment attributes to build a machine learning model to predict the outcome of Kansas Jayhawks games. Use date columns and sentiment as feature inputs into this machine learning model. Use different machine learning models and evaluate performance based on confusion matrices.\nBusiness Goal 10: Predict which team each commenter supports using the comments themselves.\nTechnical Proposal: Using two different machine learning models to predict which team each commenter supports using features from the comments dataset. Use kmeans and SVM machine learning techniques to train and test two models, then compare their accuracy and recall to determine which model is more effective for this goal. Complete other visualizations using these techniques to further examine the dataset.\n\n\n\nWe initially conceptualized this project as a comparison of professional and collegiate basketball. When we began our initial data pulls of the reddit data, we found that this data would be too big and too unweildy to complete a project like this one. Below is our overview of professional basketball and our initial proposal.\nProfessional Basketball: Professional basketball in the United States is played in the National Basketball Association (NBA). The NBA has feeder leagues (such as the G League), and there are other international leagues as well. The NBA consists of 30 teams, most if not all of which have their own subreddits. Each NBA team has 15 players, in addition to two two-way contracts between the NBA and the G League. Each player in the NBA is paid via contract, and each are eligible for any advertising or sponsorship money that they pursue in addition to their contractual responsibilities.\nPart of our analysis would’ve been analyzing the r/NBA subreddit and also the r/bostonceltics and r/warriors subreddits, as those were the two teams to make the NBA finals in 2022 (the Golden State Warriors were the 2022 NBA champions). This way, we would’ve been able to track the sentiments of the two most successful teams in the NBA across the season.\n\n\n\n\n\n\nBased on our initial business goals, we think there are a few external datasets that could be relevant. Our primary dataset will likely be the weekly rankings of college basketball teams in the 2021-2022 season. We found that dataset here, and that dataset is uploaded as a csv in the /data folder. This dataset is the top 25 rankings of college basketball teams, as voted on by a predetermined committee. These rankings come out once a week and reflect the outcomes of all of the games from the week prior. This dataset would be relevant in each of our sections because it captures lots of national sentiments around how each team is performing and their performance relative to other teams week to week. We could likely use this information to capture how teams are performing objectively and compare that to sentiments on these subreddits.\nWe will also likely need to incorporate the daily or weekly schedule of college basketball games, found here. This schedule will allow us to take reddit sentiment or posting patterns and correlate that information to games played that day, week, or month.\nWe will also likely incorporate information from viewership data, such as from this website. This can help us find which games are highly anticipated and the games that are the most viewed, and thus likely the most commented on.\nOther potential datasets we could incorporate are injury reports, potentially the reports generated before every game. This could help capture things outside of the weekly rankings or scheduling that may affect poster sentiment or poster frequency.\nWe anticipate continuing to find and use external datasets throughout the course of this project.\n\n\n\nWe also created new variables to help with our exploratory data analysis. We created variables such as comment length and submission length (across the subreddits) to find the length of post.\nAdditionally, we created a new variable taking information from the poster’s username/avatar to extract information about the poster’s fandom. This will help contextualize the comments and submissions, giving us greater insights and avenues for analysis. Extracting data from the “title” of a post we also created a “game thread” indicator column which helps separate normal submissions to game specific threads. Additional variables we created are found throughout this analysis.\nWe plan to continue developing new variables as necessary throughout this project to capture other necessary information as we continue.\n\n\n\nFinally, we created a number of dummy variables to help with our exploratory data analysis and to continue to help with other phases of analysis. Some of these dummy variables include:\n- if a game thread was about a ranked matchup (Game Thread Posts Only)\n- if a certain team was mentioned in the comment/submission post \n- What time a game was played and what teams were playing (Game Thread Posts Only)\nThese dummy variables are found throughout our analysis here."
  },
  {
    "objectID": "discussion.html",
    "href": "discussion.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "On this project, we received feedback from both Professor Amit and from fellow students, which we implemented throughout the project. We did not receive explicit feedback on the Natural Language Processing (NLP) and Machine Learning (ML) pages because of the timing of the submissions; however, we extrapolated from the feedback on the project plans, Exploratory Data Analysis (EDA), and website/result sections to ensure that our project improved as much as possible based on the feedback we received.\n\n\n\nBelow, we outline the feedback we received on each section:\n\n\n\nFeedback on Project Plans: The feedback we received from the other student group was that our project plans were well-defined and interconnected with appropriate complexity. The feedback also stated that the business goals contained no technical language and that the external datasets aligned with answering these business goals. Professor Amit did not include any specific feedback on the Project Plans, so we tried to continue what we had done on the original Project Plans throughout the site.\nImplementation of Feedback on Project Plans: Because the student feedback group thought that we met expectations in the project plans sections, we continued to implement things that they thought were good throughout the project, especially as we adapted our business goals in the NLP and ML sections. We ensured that these new and adapted business goals still contained no technical language, and we continued to use our external dataset to create the narrative flow throughout the project that the group liked. Professor Amit’s feedback did not include anything specific to the project plans, so we were sure to continue doing what we had on some of the specific project plans throughout the website. This included ensuring any changes to business goals kept the non-technical language, and any changes to the technical proposals included specific mentions of which models we would use and any other coding techniques were specified.\n\n\n\n\n\nFeedback on EDA: The feedback we received from the other student group on the EDA section included changing our tables and charts to be interactive instead of stagnant; we thought this was great feedback. The group also suggested adding more description to the tables - we thought this was great feedback as well. Professor Amit’s feedback included some things that the student group touched on, including adding interactive charts and better formatting our tables.\nImplementation of Feedback on EDA: With the student feedback in mind, we would’ve loved to make as many of the plots and graphs interactive; however, some of that we necessarily cut becuase we did not have time in this iteration of the project. We really appreciated this feedback and thought it would have made our EDA page much more interesting and engaging. We also created tables with clearer labels and provided additional explanations for the tables verbally so that the conclusions of the tables were more clear to the readers. We also ensured that our color schemes were both visually appealing and were accessible to everyone. We appreciated the group’s feedback on the section, and implemented it throughout. We appreciated Professor Amit’s feedback as well, which generally aligned with the feedback from our peers, and incorporated it into both the EDA page and throughout the website to make sure our conclusions were displayed in interesting ways and that readers were engaged in our analysis.\n\n\n\n\n\nFeedback on NLP: Although we did not receive feedback from the other student group on the NLP page because of the submission timelines, we were able to incorporate some of the feedback from the EDA sections into the NLP section. Professor Amit’s feedback didn’t touch on anything specific to NLP, so we were sure to incorporate his feedback of flagging any additional insights that we found in this section, as well as ensuring that this portion of the website was easy to navigate and visually appealing.\nImplementation of Feedback on NLP: We added increased descriptions to our tables and charts, and we focused on making our business goals have no technical language while ensuring that our technical proposals specified which models we would be using to accomplish our tasks. The feedback on the EDA section made our NLP section better as well.\n\n\n\n\n\nFeedback on ML: Similar to above, we were able to incorporate feedback from the student group on the EDA section and implement it into the ML section. Professor Amit’s feedback noted that if we found any insights outside of our initial business questions, we should highlight that and make that clear. Overall, we thought this was great feedback because it encouraged us to expand the scope of our project, and we incorporated this feedback throughout our website.\nImplementation of Feedback on ML: We added a new business question section, with new modeling and analysis, to increase our material and come to additional interesting conclusions using the data at hand. We continued to use our external data efficiently and ensured it tied to the narrative we were building throughout our project. We took some time to expand our ML section to include additional analysis, which included some of these additional insights Professor Amit suggested. We also were sure to flag anytime our business questions evolved over the course of the project, which happened a few times based on the data we had, which were also insights outside of our initial scope.\n\n\n\n\n\nFeedback on Website/Results: Our student feedback group had a few suggestions for how to improve the overall website and the results. The group suggested adding titles to the tables to ensure the readers understood what the tables meant; we incorporated that feedback on every page of the website so that each table has a title and is easy to understand for the readers. Professor Amit’s feedback suggested that the website could be made better by improving how visually appealing the site is and ensuring that the site is easy to navigate.\nImplementation of Feedback on Website/Results: We ensured that the color schemes added onto the message that we wanted readers to take away from each portion. We addressed Professor Amit’s comments by improving the layout of the website, doing a better job of labeling charts and tables, and at times adjusting the color scheme of graphs and charts to make them more visually appealing. We also incorporated this feedback by reframing the EDA site, as the original project suggested, so that the EDA site mirrored the other pages in content and structure. We think these myriad changes improved the ease of navigation and visual nature of the website.\n\n\n\n\n\nOverall, we thought the feedback was all extremely helpful, and we implemented almost all of it - as mentioned above, we ran out of time to fully make all of the plots and graphs interactive, but we thought that was great feedback and we would love to take it on as next steps in the project. We took on all of the feedback, and we even extrapolated the feedback from the EDA sections to the ML and NLP sections in order to ensure that our website was as good as possible."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA",
    "section": "",
    "text": "Please find the code for data collection here"
  },
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "Please find the code for this analysis in the notebooks located here\n\n\nOur NLP analysis led us to a number of interesting conclusions regarding user sentiment in reddit data for our chosen college basketball subreddits. We used comment frequency and sentiment to analyze things like player and team popularity, how teams react to big wins and big losses, and sentiment around team successes. First we found that there were a number of very popular players, and the popularity of these players ebbed and flowed over the course of the season. We also found that popular discussion points such as the transfer portal were discussed heavily on reddit and the amount of disucssed ebbed over the course of the season.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Disucssion of the transfer portal during the 2021-2022 season in the comments dataframe.\n\n\nThen, we examined external data about how these teams were performing and compared that to how fans were feeling about their teams. We took some top teams and saw that there was a wide distribution of feeling about them, but overall, “Cinderella” teams were viewed favorably in submissions, and each team was viewed about equally in the comments. Additionally, we examined how sentiment varied over the season for the two most successful teams, Kansas and UNC. Here we visualize the sentiment for some of the top teams in the 2022 NCAA tournament.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: The percentage of comments that are positive, negative, and nuetral for top teams in the 2021-2022 season.\n\n\n\n\n\n\n\nIn this section we performed standard NLP cleaning to clean reddit text data related to College Basketball. We then used that clean data to perform various analyses including identifying discussion on various topics related to college basketball, sentiment analysis of reddit posts, and linking reddit posts to the success of teams throughout the season.\nLet’s look at the data before it is cleaned to get an understanding of the distribution of text data.\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Distribution of text lengths in comments and submissions.\n\n\nHere we see that the distribution of text lengths in submissions and comments is heavily right-skewed, but submissions are typically longer, which makes sense as people will write more in a post than in a comment.\nIdentifying the most common words is also interesting, but looking at unclean data means the most common words will be “the”, “and”, “a”, etc. Which is not interesting. Lets clean the data first and then look at the most common words.\nThe data is cleaned using the following steps: 1. Tokenize: Create tokens from each word 2. Remove Stopwords: Remove common words such as “the”, “and”, “or”, etc 3. Lower Case: convert all words to lowercase 4. Normalize: remove non-standard words and digits, including emojis 5. Lemmatize: lemmatize all words to group the same word in different forms\nUsing the clean data let’s look at the most common words in our reddit data\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Most common words in comments and submissions after standard nlp cleaning.\n\n\nThe most common words in comments and submissions align with this being posts and comments about basketball. Words like team, game, final, and win are all sport related words. While there are differences between comments and submissions it’s not very clear that there is any pattern in the differences between the top words. We also looked at TF-IDF scores to identify the most important words, the findings of this were not as relevant with words such as: “punish”, “harris”, and “load” being the most important words so we will not further discuss those scores.\n\n\n\nTwo topics that are related to college basketball are the discussion about top players and the discussion of transfers and the transfer portal. We will look at both of these topics in our reddit data, using only the comments data as our submissions data is so limited. This section will answer business goals 4 and 5.\nWe edited Business goal 4 to remove looking at sentiment of players because the sentiment model was not completed yet. Business goal 5 was also changed so that we are not looking at specific transfers but at the discussion around transferring as a whole which was more time efficient.\nPlayers, especially the best, are heavily discussed among college basketball fans. Here we look at 9 of the best players of the 2021-2022 season. We chose these players based on their selection to first or second team all America. We removed “Johnny Davis” who was on first team all america but has such a common first and last name that we were worried about picking up discussion on other players with the same name. First we looked at the number of comments that mention each of the players. Kofi Cockburn, Keegan Murray, and Drew Timme have some of the highest mentions. It is interesting to see such a large difference in player mentions among the best players. This could be related to the team the player plays for or how flashy/controversial they are.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Number of comments in the College Basketball subreddit for each player in the 2021-2022 season. Players displayed are first/second team all americans.\n\n\nOver the course of the seasons, certain players also become more or less relevant. Here we see that over the course of the season, there is a lot of variability in which player is the most discussed. However, Keegan Murray and Jaden Ivey are definitely the most mentioned players overall. They were picked #4 and #5 in the 2022 NBA draft so it makes sense that they were so heavily discussed.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: The most discussed player in the college basketball subreddit in each month of the 2021-2022 season.\n\n\nSince the NCAA became more flexible with transfers in 2020, there has been a creation of the transfer market in College Basketball. This has led to lots of discussion among whether this is good for the players, the sport, and fans. Additionally, fans talk a lot about who might be transferring and who their team could pick up in the transfer portal. Here we see how much the transfer process is discussed over the course of the season. Transfer discussion rises from January to May, with a spike from March to May. This makes sense because most players decide to transfer after the season is over, which for most teams is in March. This means fans are very reactionary in their discussion about transfers, only talking about it when players are starting to transfer, but not so much during the regular season.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Disucssion of the transfer portal during the 2021-2022 season in the comments dataframe.\n\n\n\n\n\nWe also incorporated two datasets other than the rankings - the schedules (and win-loss records) for Kansas and UNC. These two other datasets will help us answer one of our business goals about how fans react after big wins or big losses.\nLet’s examine our two subreddits to see if there are answers to our questions there. First, we take the comment frequency analysis done in question 3 of our EDA analysis as a baseline for this question. We’ll do Kansas first:\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Number of comments per day in the 2021-2022 season in the r/jayhawks subreddit\n\n\nBased on our definition of “big wins” and using the external dataset, we determined that “big wins” occurred on January 11, January 24, February 1, February 5, March 5, March 12, March 25, and April 2. There is a spike in comments on January 24, February 1, March 5, March 25, and April 2 (which is during the end-of-season tournament), but none of these spikes are anywhere close to the comment increase around the tournament championship, which makes sense. We can see that there is an increase in engagement on this subreddit when there is a “big win.”\nBased on our definition of “big losses” and using the external dataset, we determined that “big losses” occurred on November 26 and March 1. Wow, very few bad losses for Kansas! On the message boards, the second bad loss has a slight spike. Kansas was blessed with a schedule with few bad losses - the fans seem to have benefitted from that as well. Now, we’ll do the same thing for the other school we selected, UNC.\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Number of comments per day in the 2021-2022 season in the r/tarheels subreddit\n\n\nBased on our definition of “big wins”, UNC had big wins on December 1, March 5, and throughout the tournament on March 19, March 25, and April 2. There were slight spikes in the number of comments on December 1 and on the tournament win dates, as well as a huge spike on the day of the loss to Kansas in the tournament. In this chart, there is a clear buildup from the beginning of March throughout the tournament - no other big wins stick out more than those. Based on our definition of “big losses”, UNC had big losses on January 5, January 18, January 22, February 16, and March 11. Many more than Kansas had! The two bad losses in a row in late January were met with a spike in comments - one of the largest up until that point. Additionally, the March 11 loss had a spike as well, probably many fans acknowledging their chagrin heading into the tournament. Overall, big wins or big losses did show up in the comment frequency, but the tournament results were a significantly larger change in comment frequency.\nWe will investigate whether the sentiment expressed in fan comments is influenced by the outcomes of games, particularly in cases of significant victories or defeats. This analysis will be conducted subsequent to the development and establishment of a sentiment analysis model.\n\n\n\nIn this section, we built a sentiment model and tried to find the relationship between the team ranking and the sentiment. We employ a sentiment analysis model originally trained on Twitter data for our study. The decision to apply this model to Reddit data is grounded in the shared characteristics of both platforms, including similarities in content types, language styles, topic diversity, user engagement, and the nature of online discussions. However, it’s important to acknowledge a key difference: Twitter’s character limit often results in more succinct and occasionally cryptic language, whereas Reddit allows for lengthier and more detailed comments. This disparity in content style could potentially impact the model’s accuracy in analyzing sentiment on Reddit, a factor we’ll carefully consider in our analysis.\n\n\n\nIn our previous exploration within the EDA section, we focused on quantifying the mention frequency of ten basketball teams. In our current analysis, we delve deeper by leveraging sentiment analysis models to dissect the emotional tone embedded within submissions and comments that reference each team. This sentiment distribution offers a nuanced perspective, going beyond mere mention counts to encapsulate the nature of the discourse surrounding these teams.\n\n\n\n\n \n\n\nFigure 10: The percentage of comments and submissions that are positive, negative, and nuetral for top teams in the 2021-2022 season.\n\n\nIn both submissions and comments, a pronounced positive sentiment prevails across the board for all teams, with the positive sentiment—represented by green segments—forming the bulk of the sentiment distribution. Negative sentiments are relatively few, and neutral sentiments are even rarer. Among submissions, Saint Peters and Miami stand out with a substantially higher share of positive sentiment. However, Saint Peters’ data is limited to just four entries, casting doubts on the reliability of these results. Miami’s data is more substantial, suggesting a positive reception or favorable outcomes in related games. Yet, the unusually high volume of submissions for Miami warrants additional investigation to fully understand the drivers of this positive sentiment trend. Conversely, the sentiment distribution within comments is more uniform across teams, lacking any significant disparities.\n\n\n\n\n \n\n\nFigure 11: Point differential for Kansas and UNC compared with the sentiment of their respective subreddits in 2021-2022. Green bars indicate wins where larger wins are larger bars, whereas red bars indicate losses. The green and red lines indicate number of positive and negative posts, respectively.\n\n\nOur investigation intensifies as we probe into the impact of match outcomes—especially resounding triumphs or losses—on the emotional tone within fan discourse. Focusing exclusively on Kansas and North Carolina, their status as the champion and runner-up offers a compelling lens through which to assess the interplay between on-court results and sentiment in fan commentary.\nThe figure suggests a weak correlation between the volume of comments and the game’s point differential. Contrary to expectations, a decisive victory doesn’t necessarily lead to an increase in positive comments or a decrease in negative ones. Similarly, a substantial defeat doesn’t always trigger a rise in negative comments or a fall in positive ones. Additionally, the trends in positive and negative comments appear to move in tandem; an increase in one typically accompanies a rise in the other, as indicated by the symmetrical nature of the lines on the chart.\nCertainly, significant victories don’t always equate to substantial point differential. Consider a top-seeded team overpowering a lower-ranked opponent by a wide margin; such outcomes rarely stir enthusiasm or provoke widespread discussion. It’s crucial to factor in the caliber of the opponent and various other elements. However, even when accounting for the big wins and losses we’ve examined before(Section 4), there isn’t a discernible difference between the nature of the comments, be they positive or negative. This observation appears to reinforce our conclusion.\nAdditionally, it’s vital to assess the model’s effectiveness in accurately identifying the sentiments expressed in the comments. Comments on sports events may possess unique characteristics that a sentiment model, trained predominantly on Twitter data, might not capture. This discrepancy could contribute to the lack of clear distinction between positive and negative emotions in our analysis.\nOn another note, fan reactions to a team’s performance are often diverse and complex. A significant victory might elicit sheer joy from some fans, while others might express concern. Similarly, in the face of defeat, while some fans may express sorrow or disappointment, others might offer encouragement to the team and players, showing resilience. There’s even a possibility that the fans’ comments are indifferent to the game’s outcome, focusing instead on different aspects. This underscores the need for more comprehensive research to validate these observations.\n\n\n\nOur external data centered around answering our business questions by providing the weekly rankings of each team and the results throughout the year of the two teams we chose to focus on: Kansas and UNC. These results were incorporated throughout the answers to the business questions above. The rankings were interesting, especially because one of our teams, UNC, was rarely in the Top 25 (they were somewhat of a Cinderella story!). This gives us some interesting data points on how fans of teams outside of what experts view as the top teams behave. Overall, the rankings were chaotic in the 2021-2022 season, as shown here:\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: The AP top 25 ranking of each team over each week in the 2021-2022 college basketball season\n\n\nVery few teams made it to the number one spot, and the ones that did rarely stayed there long! Although clearly these rankings don’t always mean something – shown by UNC’s run to make it all the way to the championship game despite rarely being ranked all season – it is useful to have a metric to compare teams to others, especially in the face of ecstatic fanbases."
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "Conclusion: Overall, we were able to take reddit comment data to draw interesting conclusions about the world of college basketball. Through exploratory data analysis (EDA), natural language processing (NLP), and machine learning (ML), we were able to draw non-obvious conclusions from text data referring to different teams, players, and games. We used time of comment, length of comment, and substance of comment to answer our business questions. In conclusion, although we didn’t always find correlations or accurate models throughout this process, we were able to see interesting patterns and trends over the course of the 2021-2022 college basketball season.\nIn the EDA section, we saw some interesting trends in comment frequency and timeliness, shown as follows:\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: A count of comments per day in the /jayhawks subreddit over the 2021-2022 season.\n\n\nFor example, with the eventual champion, the Kansas Jayhawks, there was a general stasis of comments that spiked a few times a month when important games occurred, but there was a huge spike at the beginning of April, when Kansas won the NCAA Championship. This was useful EDA baselining so that we understood more about what the data looks like and how redditor posters behaved throughout a typical season.\nIn our NLP section, we saw some interesting things, especially when we went down to the team-specific level:\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: A count of comments per day and their associated sentiments over the 2021-2022 season.\n\n\nThis chart indicates positive or negative sentiments in comments on each specific day. Although we expected to see a strong correlation between game outcomes and comment sentiment, we actually didn’t see that - this was our first hint that reddit posters operate outside of game outcomes, and often post on a wide variety of topics that range outside of the scope of just wins and losses.\nIn the machine learning section, we saw some interesting trends as well, including how popular a comment is. We were able to construct a model with the following accuracy:\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: A count of comments per day and their associated sentiments over the 2021-2022 season.\n\n\nIn this model, we were not able to relatively accurately predict the popularity of comments when the true. Improving this model is among the next steps of our project.\nPlanned Next Steps: As mentioned above, one of the possible next steps for this project include continuing to hone the accuracy of ML models to predict comment popularity. Next steps also include continuing to make other graphs and plots interactive to improve the readability and interactivity of the website, building out comment frequency patterns for teams other than the Jayhawks and Tarheels, and completing similar analyses across seasons to see if the patterns we found held. We also would like to incorporate more external datasets to improve our analysis, including how some of the popular players or popular transfers fared once they arrived in professional basketball leagues. We could also complete a similar analysis on the r/NBA subreddit and see if our conclusions held there too. All of these planned next steps would improve our project and expand our analysis if we chose to partake in them.\nOverall, we found this project to be interesting and enjoyable - the topic was engaging and we were challenged to use big data techniques to deal with this dataset and extract interesting conclusions from it. Thank you for walking through this project with us!"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "Please find the code for this analysis in the notebooks located here\n\n\nIn our machine learning endeavors, we delved into various factors potentially influencing review popularity and employed a random forest model for predictive analysis. The findings reveal that the length of a comment, the author’s activity, and immediate temporal factors—like hours and days—are strongly associated with the likelihood of a comment’s popularity. However, the model’s predictive performance is suboptimal, exhibiting a discernible bias. This limitation is intimately linked to the inherent distribution of the comments scores, suggesting that the model’s accuracy is contingent upon the underlying data characteristics.\nThen, we use two different machine learning models to predict which team each commenter supports using features from the comments dataset. We use k-means and SVM machine learning techniques to train and test two models, then compare their accuracy and recall to determine which model is more effective for this goal. Both of these models did not perform well. The lack of performance can be attributed to both the lack of predictive ability in the comments data and also the large number of potential teams a commenter can support.\n\n\n\nA note: the business goals have changed from our original goals. Upon further exploration of the dataset, it has become apparent that our initial business objectives no longer align with the insights gleaned from the data. For instance, the anticipated correlation between the sentiment of comments and contest outcomes did not materialize as strongly as expected, casting doubt on the practicality of leveraging comment sentiment to forecast contest results. Consequently, we have pivoted our focus to previously unexamined aspects of the data, such as the popularity of comments, to ensure that our business goals remain rooted in the actionable intelligence derived from our analysis.\n\n\nBusiness Goal: Predict which comments are more popular than others in the College Basketball subreddit\nTechnical Proposal: Determine why certain comments are more popular than others in the College Basketball subreddit. Using Random Forest Regressor to identify if factors such as sentiment, time of post, date of post, comment length, activity of author, and whether or not the author has a team icon for their profile picture are relevant in determining how popular a post will be.\nScores Distribution In this section, popularity is determined by “score” which is calculated by upvotes-downvotes on the comment.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: The summary statistics for the “Score” variable in the comments dataframe. Score can be used to represent popularity.\n\n\nIt is clear that there is a wide variation in the scores, with many posts deviating significantly from the average. To enhance readability, we focus on scores range from -20 to 80.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: The distribution of the “score” variable in the comments dataset. The x axis is limited to -20 to 80 so that we can focus on the majority of the data. Values go up to 5360\n\n\nAccording to the histogram, the scores are heavily concentrated around the lower end, indicating that the majority of posts receive a score within a narrow range close to zero. This is consistent with typical social media behavior, where most content receives little engagement. The distribution is right-skewed, meaning there are a few posts with very high scores, but these are exceptions rather than the rule. This skewness can affect predictive modeling because it suggests that high scores are outliers.\nSimple regression model\nWe attempt to predict score of a comment (popularity) based on the following: - team_index: whether the author has a supported team in their profile picture - month_vec: what month the post is from - sentiment_vec: what the sentiment of the post is - year: what Year the post is from - day: what day the post is from - hour: what Hour of day the post is from - comment_length: length of the post - author_activity: how much the author has commented in this dataset\nThe first model is a simple random forest with maxDepth=5, and numTrees=50.\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: True score vs predicted score for the simple random forest. X axis is limited to -20 to 80 so that the plot is more readable. Data has been downsampled from the full test set to show ~10,000 points, for readability.\n\n\nThe Root Mean Squared Error (RMSE) stands at 37.55, a figure that significantly overshadows the expected range of scores, suggesting that the model’s predictions often miss the mark by a wide margin. Additionally, an examination of the scatter plot reveals a pronounced accumulation of data points in the lower score region, with a conspicuous absence of predicted values in the upper echelons of actual scores. This pattern implies a propensity of the model to approximate towards the median, underscoring its limitations in forecasting scores at both ends of the spectrum. The model’s inclination to underestimate particularly high scores is especially apparent. Such limitations could stem from the inherent simplicity of the model, the characteristics of the chosen features, or the predominant concentration of lower scores within the training data. Typically on Reddit, a platform characterized by its right-skewed score distribution, posts garnering a vast number of upvotes are exceptional. Consequently, the model’s struggle to predict these rare, high-scoring outliers is not an anomaly but rather a challenge commonly encountered in the predictive modeling of social media interactions.\nComplex regression model\nIncreasing the number of trees in the random forest from 50 to 200 to give the model more complexity. Also increasing the max depth from 5 to 10 to increase complexity as well.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: True score vs predicted score for the more complex random forest. X axis is limited to -20 to 80 so that the plot is more readable. Data has been downsampled from the full test set to show ~10,000 points, for readability.\n\n\nAs the model’s complexity is enhanced, there is a marginal reduction in the RMSE to 37.25, suggesting a nuanced improvement in predictive accuracy. The model now presents a broader spectrum of predicted scores, implying a more nuanced capture of the data’s inherent variability and potentially a more accurate reflection of the underlying dynamics.\nNotably, the central concentration of predicted scores persists, yet there is a discernible uptick in the model’s proficiency at approximating higher scores, particularly those under 40. This improvement is likely attributable to the model’s deepened analytical capacity, which now teases out more intricate data patterns. However, the model continues to show limitations in predicting very low scores, with no predictions falling below zero.\nDespite the enhanced capacity to predict higher scores, a tangible disconnect remains between the uppermost actual scores and their predicted counterparts. The model demonstrates a persistent, albeit slightly reduced, propensity to favor a more constrained range of predicted scores than what the actual scores exhibit. In summation, the more complex model displays an expanded prediction range and a modest enhancement in forecasting higher scores. Yet, it is imperative to weigh these incremental advancements against potential overfitting risks and the demand for greater computational resources. Consequently, increasing complexity brings no clear advantages.\nFinally let’s check the model’s feature importance table.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Variable importance in the complex random forest model.\n\n\nThe table indicates that comment length is the most critical determinant of popularity according to the model, with its high importance score implying that lengthier comments, possibly due to their depth or visibility, tend to engage users more effectively. Author activity is also a significant predictor, nearly matching the influence of comment length, which suggests that authors who comment frequently may benefit from increased visibility or an established presence within the community, thus boosting the appeal of their posts. Temporal factors like the time of day and the date of the posting are influential as well, hinting at a correlation with peak activity periods, possibly linked to significant events such as key games that drive user engagement. The importance scores of other features are relatively low. For example, the sentiment of comments has little impact on the model’s predictions. This is consistent with our previous observation that sentiment is not strongly correlated with contest results, leading to a change in our business goals.\n\n\n\nBusiness Goal 9: Build a model that predicts the results of Kansas games.\n\nTechnical Proposal: Use sentiment analysis and comment attributes to build a machine learning model to predict the outcome of Kansas Jayhawks games. Use date columns and sentiment as feature inputs into this machine learning model. Use different machine learning models and evaluate performance based on confusion matrices.\nTo answer this question, we were working to see if the result of a basketball game could be extracted from the time and the sentiment of the comments on the day before the game and the day after the game.\nThe available dataset included the comments under three subreddit including ‘CollegeBasketball’, ‘jayhawks’, and ‘tarheels’. We chose to focus on the Kansas games, so the comments in the “tarheels” subreddit are not relevant for this goal. Therefore, we filtered the dataset to get the comments in the both ‘CollegeBasketball’ and “jayhawks” subreddits and selected the columns including “day”, “month”, “year”, “week” and “col”. The target column is in the external dataset named “kansas_schedule.csv” in the folder “data/csv”. This external dataset is about the results of the games where Kansas played, and the results information is in the column named “Unnamed: 8”. Thus, we joined these two data frames together so that we could use machine learning pipelines to do prediction analysis.\nWe tried three different models for classification: two random forest models with varying number of trees (model 1 using random forest with 20 trees and model 3 with 10 trees) and model 2 using logistic regression. Then we compared the results and got the table below.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Table of three machine learning models and their accuracies.\n\n\nFrom this table, we chose the third model, a random forest model with ten trees to make further analysis by the confusion matrix. And then, we got the confusion matrix like the graph below.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Confusion Matrix of random forest machine learning model.\n\n\nFrom the confusion matrix, we were surprised that the prediction performance was satisfactory. It seems that using the time and the sentiment of the comments can help make predictions for the result of the upcoming Kansas game, which is interesting.\n\n\n\nBusiness Goal: Predict which team each commenter supports using the comments themselves.\nTechnical Proposal: Using two different machine learning models to predict which team each commenter supports using features from the comments dataset. Use kmeans and SVM machine learning techniques to train and test two models, then compare their accuracy and recall to determine which model is more effective for this goal. Complete other visualizations using these techniques to further examine the dataset.\nFor the second part of this section, we chose to to use two models: one kmeans model and one SVM model. We intended to use each comment to predict which team each commenter supported. Our accuracy scores were very low for this portion, which we will discuss below.\nFor the first kmeans model, we got the following results:\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Results for the kmeans model\n\n\nThis model alone shows us a few things. First, it has a very low accuracy. That tells us that it is very difficult to predict which team each commenter supports just by using what they comment on. That leads us to our second conclusion: that posters write about things beyond their own teams. This gives us insight into the college basketball poster atmosphere writ large, as people are interested in teams outside of just their own bubble. Now, we’ll see if we can increase the accuracy of prediction by using a different model.\nFor the second model, the SVM model:\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Results for the svm model\n\n\nInteresting! This model had a very slightly higher accuracy, although not by much. This confirms our analysis from running the first model: that predictions based on what people comment about are very hard, and one theory behind that is that college basketball has a robust community of commenters who each care about games beyond who their own team is. This is also relevant because at the end of the season, 64 teams are in a tournament to win the championship, so each fan needs to be very engaged to be ready for the end of the season. This is one theory about why these accuracy scores shown here are so low; there are certainly others.\nAdditionally, here is a chart (a confusion matrix) to show how the SVM model performed:\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Confusion matrix for the SVM model\n\n\nAs you can see, the confusion matrix revealed that most, if not all, of the model was extremely inaccurate. There were slight trends in a few areas that the model has some success predicting, but overall, this was not an accurate result, and this model does not have any predictive power.\nAs an additional section, we conducted some additional machine learning on using kmeans to create word clouds out of three clusters that we initially created. In these word clouds, the most common words in each cluster were:\n\nCluster 0 Top Keywords: just, lol, team, don, year, think, fuck, time, big, foul\nCluster 1 Top Keywords: like, good, just, team, looks, don, really, year, feel, think\nCluster 2 Top Keywords: game, just, like, win, good, team, refs, play, ve, watch\n\n\n\n\n\n  \n\n\nFigure 11: Word Cloud for the K-means model clusters"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "College Basketball Reddit Project",
    "section": "",
    "text": "This project will use the given Reddit data to explore how Reddit users view, react to, and analyze collegiate basketball. We will compare sentiments and use external datasets such as team records and rankings to better understand how Reddit users react to their team successes or failures. This project will center around three different areas of analysis: exploratory data analysis (EDA), natural language processing (NLP), and machine learning (ML). We expect these three different areas of analysis to display different areas of the dataset and allow us to answer a variety of questions about this data. We will use the Reddit data to explore the differences in sentiment between collegiate basketball fans and how the fans of the top teams from 2021-2022 reacted over the course of the season. We chose to limit our data to 2021-2022 because we wanted to ensure that our data captured an entire basketball season and no partial seasons. The collegiate season ranges from November to about March, so by taking our data from September 2021 to April 2022, we are able to ensure that we can capture the data from an entire basketball season.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Source: Carmin, Mike. (September 16 2020). NCAA to start basketball season Nov. 25; Big Ten decision up next. https://www.jconline.com/story/sports/2020/09/16/ncaa-start-basketball-season-nov-25-big-ten-decision-up-next/5813674002/\n\n\n\n\n\nAlthough professional and collegiate basketball are very related, there are some key differences that we want to establish before engaging in any exploratory data analysis. We expect these differences to become apparent in some of our sentiment analysis, NLP, and even in the exploratory phase of this project. Collegiate Basketball: Collegiate basketball in the United States is regulated primarily by the National Collegiate Athletic Association (NCAA). For the purposes of this project, we will be focusing on NCAA division 1 (D1) college basketball. College basketball is sorted into conferences (which typically align across sports for schools), which determines most of each team’s scheduled opponents and the conference championship tournament. At the end of each season, there is a gigantic tournament to determine the college basketball champion, colloquially called March Madness. In March, 64 teams (plus four other teams who play a “play-in game”) compete in a single-elimination tournament to determine the champion for the season. These players are considered amateurs, i.e. they do not receive contracts, but each collegiate basketball player is eligible to receive sponsorships and advertising revenues.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Source: NCAA. Championship History. https://www.ncaa.com/history/basketball-men/d1\n\n\nPart of our analysis will be analyzing the r/CBB (college basketball) subreddit, but we will also be analyzing the r/jayhawks and r/tarheels, the two teams to make the finals for college basketball in 2022 (Kansas won!). This way, we can also track the sentiments of the fans of the two most successful college basketball teams across the course of the season on their championship runs.\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Source: Withrow, Lauren. (April 5, 2022). Kansas named 2022 NCAA Men’s Basketball Champion after record-setting comeback victory over North Carolina. https://www.si.com/college/northwestern/basketball/kansas-named-2022-ncaa-mens-basketball-champion-after-72-69-comeback-victory-over-north-carolina\n\n\n\n\n\nAs the project progressed, we made a few changes to the business goals as we learned more about the data and our own capabilities. You can find the finalized versions of those buisness goals on the Business Goals section of this site."
  },
  {
    "objectID": "eda.html#executive-summary",
    "href": "eda.html#executive-summary",
    "title": "EDA",
    "section": "Executive Summary",
    "text": "Executive Summary\nIn the initial analysis of our college basketball reddit data we collected data from three subreddits: “CollegeBasketball”, “tarheels”, and “jayhawks”. Before starting more complex topics such as natural language processing and machine learning on this data it is important to understand the data you are working with and in this exploratory data analysis section we do just that. First we take a look at the individual dataframe itself and do some basic cleaning to remove missing and select only relevant columns. Then using data transformation we are able to identify that the most supported teams in the college basketball subreddit include Florida State, Illinois, and Purdue. We also identified some of the most talked about games with the number one obviously being the national championship. Using these findings we dug deeper into the eda.\nOur first business goal was to look at how reddit activity changes overtime and an interesting finding was that reddit activity in the comments section of the subreddit is weekly and hour of day cyclical, meaning that activity correlates with when games are played during the season. Furthermore, we also wanted to identify which teams are the most discussed during the season. We found that popular teams like Miami, Kansas, North Carolina, and Purdue were the most discussed. These findings along with the rest of our eda motivated the other analysis in this project."
  },
  {
    "objectID": "eda.html#analysis-report",
    "href": "eda.html#analysis-report",
    "title": "EDA",
    "section": "Analysis Report",
    "text": "Analysis Report\n\nDataframe Analysis\nThe first step in any data analysis is to explore the dataframe. In this first section of our eda we will explore the data that we collected which contains submissions and comments data of the r/CollegeBasketball, r/tarheels, and r/jayhawks subreddits between September 2021 and April 2022 (The approximate length of the College Basketball Season). No additional cleaning has already been done on this data. The full code for this analysis can be found here.\n\nSubreddit Analysis\nThe breakdown of the 3 subreddits by number of posts is heavily imbalanced as is expected. In submissions there are just over 22,000 posts and in comments there are just over 1,575,000 comments. The majority of these posts come from the CollegeBasketball subreddit.\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Number of submissions and comments in each of the 3 subreddits used in this project.\n\n\n\n\nSchema\nThe important variables in the submissions dataframe are\n\nsubreddit: The Subreddit that the post is in\nauthor : Who authored the post\nselftext : The contents of the post\ncreated_utc : The timestamp of the post\n\nThe important variables in the comments dataframe are\n\nsubreddit: The Subreddit that the post is in\nauthor : Who authored the post\nbody : The contents of the post\ncreated_utc : The timestamp of the post\nscore: Upvotes - Downvotes on the comment\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: The schema of the submissions and comments dataframe\n\n\n\n\nMissing Data\nSince Reddit is a user driven platform there will likely be issues with missing text in posts or deleted posts/comments. In the comments dataframe there are 85,295 data points with no value for the body column and in the submission dataframe there are 12,348 missing values in the selftext column. Once we remove these datapoints the number of datapoints in each subreddit looks as follows:\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Number of submissions and comments in each of the 3 subreddits used in this project, after missing values have been removed.\n\n\n\n\nPreliminary Data Snapshot\nNow we can look at the preliminary data for the first time.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Example rows from the submissions and columns dataframe after missing values have been removed.\n\n\n\n\nCreating New Columns\nauthor_flair_text is a column that contains information about the user icon of the reddit user. In most of these posts this is the team that the author supports. We created a new column that extracts the team information from this column to get a representation of which team a user supports. In submissions the most common icons are the default rcbb (r/collegebasketball) and None (no icon). Ignoring those we see that the most supported teams are Florida State, Illinois, Purdue, and Duke. In comments, None is the most common icon, however after that the most supported teams are Purdue, North Carolina, Illinois, and Kentucky. This shows that some fan bases may be more active posters while others may be more involved in the comments section.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: The most supported teams in the submissions and comments dataframes based on user icons.\n\n\nSome posts in the submissions of r/CollegeBasketball are game threads where people can comment on and discuss specific games that are being played. We can extract information about the title to determine the teams playing in the game, their rankings, and the time the game is being played. From here we can determine which games have the most comments and thereby can act as a proxy for which games were the most watched on reddit. We see that the most commented on games involve North Carolina, and further analysis of these games show that the three most popular games are the Elite Eights, Final Four, and Championship games for North Carolina. Additionally we see that all of the most popular games are between ranked teams.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: The games with the most comments under the respective game thread in the 2021-2022 College Basketball season.\n\n\nExpanding on this finding that ranked matchups seem to have more interest we did some further analysis to look at the popularity of games over the course of a season and also the difference between ranked and unranked mathcups. Here we see that ranked matchups have significantly higher average number of comment in all months of the season. If we compare only February, ranked matchups have on average 12.5 times the number of comments of unranked matchups. Additionally we see that April and March have the highest number of average comments across both groups, while the earlier months in the season (November and December) have lower average comments per game.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: The average and total number of comments grouped by month and whether or not the game is a ranked matchup.\n\n\n\n\n\nBusiness Goal 1\nGoal: Determine how reddit activity ebbs and flows over the course of a collegiate basketball season. Construct visuals to aid in understanding how much reddit users post over the course of the 2022 season.\nCode for this analysis\nTo answer this business goal we first want to simply look at the trend of reddit posts/comments by day over the course of the season in the following figure. Given that the first college basketball game in this season was November 9th, 2021 these counts of comments and submissions per day make sense. We see lower comments and submissions leading up to the season. This is where the two groups deviate. Submissions spike right at the beginning of the season (lots of fans critiquing or praising their new look teams perhaps?), then we see a drop off in submissions as the season settles in, followed by a rise up to the tournament in March, with a quick drop off in the middle of March as many teams are eliminated from contention for the title. Comments, on the other hand are relatively low at the start of the season, and see a rise up until the NCAA tournament in March/April. This indicates that commenting is perhaps more common later in the season as competition because more important and the NCAA tournament gets closer. Submissions are more steady perhaps because these are longer posts that mostly year long fans write.\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: The number of reddit submissions and comments each day in the r/CollegeBasketball subreddit during the 2021-2022 College Basketball Season.\n\n\nWe also wanted to look at the average number of words per post/comment to give another angle by how to analyze “reddit activity”. Number of posts is one way to look at it, but it can also be important to see how much time people spend writing these posts and comments. We see this in the figure below. In the comments dataframe we see that the average length each comment is longer before the season starts (November 1st), than during the season (November 1st - April 5th). This is likely because of the lack of posts during the preseason as we saw the in the previous graph. It does say something interesting though that the few people who do comment in the subreddit during the offseason, typically are writing longer comments. In the submissions dataframe we see a different trend. The offseason has fewer or the same average words per submission, however we do see some spikes. After digging into these specific days we identified that these spikes with 600+ words per day occured on days with very few posts (&lt;5) and one of those posts was particularly long. For example on September 2nd, 2021 one user detailed their year long simulation of which college basketball teams were the most lucky, and on October 17th, 2021 another user listed each college basketball team where the first letters of the teams names were swapped (Tar Heels = Har Teels). The spike in March of 2022 for submissions is the same day as the start of the 2022 NCAA Basketball Tournament.\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: The average number of words in reddit submissions and comments each day in the r/CollegeBasketball subreddit during the 2021-2022 College Basketball Season.\n\n\nOne final way we want to analyze the reddit activity during the college basketball season is to look at the number of comments as a weekly and daily cyclical trend. College Basketball games are usually played on weeknights and all day on the weekends, lets see if the distribution of comments align with when the games are played. The heatmap below shows the distribution of comments over hour of the day and day of the week. The highest density for total comments are around 9pm Tuesdays and Thursdays and around 2pm Saturdays. In general we also see weekdays having more comments after 5pm, while Sundays and Saturdays have more even distribution througout the day. This aligns with when college basketball games are typically played and indicates that the CollegeBasketball Subreddit is much more active when games are currently being played.\nNote: The plot uses Eastern Time as many games are played in EST, but there may be some issues with Central, Mountain, and Pacific time games. Since all games are played within 3 hours of eastern time we did not find this to be a fatal issue, but it must be considered during analysis.\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: A heatmap of the number of comments broken into day of the week and hour of the day.\n\n\n\n\nBusiness Goal 2:\nCode for this analysis\nGoals: Explore how the subreddit page of the NCAA champion in 2022, the Kansas Jayhawks, varied over the course of the season. Identify any trends in post frequency or comment length that may correlate to on-the-court successes or failures.\nExplore how the subreddit page of the NCAA runner ups in 2022, the UNC Tarheels, varied over the course of the season. Identify any trends in post frequency or comment length that may correlate to on-the-court successes or failures.\n\nKansas (jayhawks) Subreddit\nIn order to analyze these subreddits, we’ll begin by diving into the comment and submission frequency for r/jayhawks.\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: The daily comment frequency during the 2021-2022 college basketball season in r/jayhawks\n\n\nThis showed us some interesting things right off the bat about this subreddit. First, the primary thing that sticks out about this graph is that by far and away, the most comments occur in late March and early April. This aligns perfectly with earlier hypotheses that the most interaction on this subreddit would be during the NCAA March Madness tournament.\nTaking this a step further, the Jayhawks won the NCAA Championship on 4 April 2022. This aligns perfect with the huge spike - which is likely that championship game. According to Forbes, this was the most-watched NCAA final game in history, so this spike correlates nicely with that!\nThere is a general “buzz” about the Jayhawks primarily during the collegiate basketball season - November through April. Our data only includes the CBB season, but we can extrapolate from the near-zero comment rate in September that there is not much excitement around the team other than during the season - to include big recruiting commitments.\nBefore the season, fans identified a number of games that were must watches: December 11, December 21, January 1, January 22, January 29, among others. Although there were potentially smaller spikes in comments during these games, there were vastly outweighed by the increased rate of comments during the finals and the NCAA tournament.\nThis will help inform our analysis in the future: because the number of comments on this page was so much smaller than on the main r/CollegeBasketball page, our analysis may be more prescient taking Kansas mentions on that main page and using that information instead of focusing on this subreddit.\nLet’s do the same thing for submissions and see if we get a similar result.\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: The daily submission frequency during the 2021-2022 college basketball season in r/jayhawks\n\n\nThere were so few submissions on the page that the maximum number of submissions in one day was eight! This tells us a lot about how Jayhawk fans react - they don’t do it on this page! Maybe there is more interest on the larger page - maybe there is increased engagement there, and that is preferable for Jayhawk fans. We’ll be able to find that out in the next EDA question.\n\n\nNorth Carolina (tarheels) subreddit\nIn order to analyze these subreddits, we’ll begin by diving into the comment and submission frequency for r/tarheels.\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: The daily comment frequency during the 2021-2022 college basketball season in r/tarheels\n\n\nThat’s a good start! This is interesting to compare to the r/jayhawks analysis of before.\nThe commenting patterns and spike follow the same pattern as the r/jayhawks subreddit. There is minimal engagement before the tournament, with some excitement building in February and March. Then, during the main tournament and especially during the 4 April championship game, there is a huge spike in comments!\nA number of games were identified by fans as must-watch throughout the season. The following is an excerpt from the linked article about the games the fandom was most excited for:\nNorth Carolina at Duke, March 5 – It’ll be the swan song at Cameron for Mike Krzyzewski, and it comes, of course, against rival North Carolina. The atmosphere in this one will be insane. Coach K announced he will retire after this season, and his final home game is against the Tar Heels in the ACC regular-season finale. I can’t wait to see what the resale market looks like for this matchup.\nDuke vs. Kentucky, Nov. 9 in New York – This is Coach K vs. John Calipari for one final time in the Champions Classic, basically opening the college hoops season. Both come off disappointing campaigns, and both will have a chance to get some early momentum this year. It’ll also feature two of the top frosh in the country: Duke’s Paolo Banchero and Kentucky’s TyTy Washington.\nGonzaga vs. Duke, Nov. 26 in Las Vegas – Two of the best programs, and arguably the two best freshmen, go up against one another at T-Mobile Arena. The Zags have long and skilled 7-footer Chet Holmgren, while Duke will rely heavily on big, strong and athletic forward Paolo Banchero.\nGonzaga vs. UCLA, Nov. 23 in Las Vegas – A rematch of the Final Four matchup in which Jalen Suggs hit the memorable game-winning shot, and both are contenders to cut down the nets this year.\nTexas at Gonzaga, Nov. 13 – New Longhorns coach Chris Beard takes his team to Spokane and will face Drew Timme, Chet Holmgren and the top-ranked Zags. It’s a chance for Texas and all of Beard’s transfers to show they are for real.\nVillanova at UCLA, Nov. 12 – A matchup of two top-five teams out at Pauley Pavilion. Villanova brought back a pair of fifth-year guys in Collin Gillespie and Jermaine Samuels, while UCLA will be led by March Madness star Johnny Juzang.\nTexas at Texas Tech, Feb. 1 – This is one you need to be in Lubbock for to truly appreciate the atmosphere. It won’t exactly be a heartwarming homecoming for Chris Beard. Sure, he led the Red Raiders to a national title game appearance and an Elite Eight, but the fans in Lubbock still can’t come to grips with why he’d leave for UT. In fact, they strongly dislike Beard now. This is his first appearance back in Lubbock, and it’ll be interesting to see the reception he receives from the fan base. I don’t expect a lot of pleasantries.\nKentucky at Kansas, Jan. 29 – It’s Kentucky vs. Kansas in the Big 12/SEC Challenge at Allen Fieldhouse. Need I say more?\nAs per the r/jayhawks subreddit, although there may have been a spike on these dates, nothing compares whatsoever to the spike around the championship engagement.\nJust as before, we’ll do the same thing for submissions.\n\n\n\n\n\n\n\n\n\n\n\nFigure 14: The daily comment submission during the 2021-2022 college basketball season in r/tarheels\n\n\nWow! There were many fewer submissions on the tarheels subreddit than the jayhawks subreddit. This could, again, be due to a number of reasons, and maybe the engagement on the main page makes up for this difference. We’ll have to see in our next portion of EDA!\nWe found that many of the questions that arose during our question 3 analysis aligned nicely with the next step of our process: finding which team mentions in the main subreddit occurred the most often. Please see our EDA Question 3 for more information.\n\n\n\nBusiness Goal 3\nCode for this analysis\n\n\nCode\n# Setup - Run only once per Kernel App\n%conda install openjdk -y\n\n# install PySpark\n%pip install pyspark==3.4.0\n\n# install spark-nlp\n%pip install spark-nlp==5.1.3\n\n# restart kernel\nfrom IPython.core.display import HTML\nHTML(\"&lt;script&gt;Jupyter.notebook.kernel.restart()&lt;/script&gt;\")\n\n\n\n\nCode\n# Import pyspark and build Spark session\nfrom pyspark.sql import SparkSession\n\nspark = (\n    SparkSession.builder.appName(\"PySparkApp\")\n    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n    .config(\n        \"fs.s3a.aws.credentials.provider\",\n        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n    )\n    .getOrCreate()\n)\n\nprint(spark.version)\n\n\n\n\nCode\nimport time\nimport sagemaker\nfrom sagemaker.spark.processing import PySparkProcessor\n\nsession = sagemaker.Session()\nbucket = session.default_bucket()\noutput_prefix_sub = \"project/comments_sub\"\ns3_output_path = f\"s3a://{bucket}/{output_prefix_sub}\"\n\nprint(f\"reading comments from {s3_output_path}\")\ncomments = spark.read.parquet(s3_output_path, header=True)\nprint(f\"shape of the comments dataframe is {comments.count():,}x{len(comments.columns)}\")\n\nsession = sagemaker.Session()\nbucket = session.default_bucket()\noutput_prefix_sub = \"project/submissions_sub\"\ns3_output_path = f\"s3a://{bucket}/{output_prefix_sub}\"\n\nprint(f\"reading submissions from {s3_output_path}\")\nsubmissions = spark.read.parquet(s3_output_path, header=True)\nprint(f\"shape of the submissions dataframe is {submissions.count():,}x{len(submissions.columns)}\")\n\n\n\n\nCode\nsubmissions = submissions.cache()\ncomments = comments.cache()\n\nsubmissions = submissions.filter((submissions.selftext != \"\") & (submissions.selftext != \"[deleted]\")& (submissions.selftext != \"[removed]\"))\ncomments = comments.filter(comments.body != \"\")\n\nfrom pyspark.sql.functions import col\n\nsubmissions = submissions.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\").filter(col(\"subreddit\") == \"CollegeBasketball\")\ncomments = comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"created_utc\").filter(col(\"subreddit\") == \"CollegeBasketball\")\n\n\n\n\nCode\n# Define a dictionary of teams and associated keywords\nteam_keywords = {\n    'houston': ['houston', 'cougars', 'uh', 'uh cougars'],\n    'kansas': ['kansas', 'jayhawks', 'ku', 'rock chalk', 'ku jayhawks'],\n    'villanova': ['villanova', 'wildcats', 'nova', 'villanova wildcats'],\n    'duke': ['duke', 'blue devils', 'duke blue devils'],\n    'arkansas': ['arkansas', 'razorbacks', 'hogs', 'u of a', 'arkansas razorbacks'],\n    'saint peters': [\"saint peter's\", 'peacocks', \"saint peter's peacocks\", 'saint peters', \"st. peter's\", 'st peters', 'spu'],\n    'north carolina': ['north carolina', 'tar heels', 'unc', 'unc tar heels'],\n    'miami': ['miami', 'hurricanes', 'um', 'miami hurricanes'],\n    'purdue': ['purdue', 'boilermakers', 'purdue boilermakers', 'pu'],\n    'illinois': ['illinois', 'fighting illini', 'illini', 'u of i', 'university of illinois']\n}\n\nfrom pyspark.sql.functions import lower\n\n# Lowercase the text fields for uniformity\ncomments = comments.withColumn('body', lower(col('body')))\nsubmissions = submissions.withColumn('title', lower(col('title')))\\\n                         .withColumn('selftext', lower(col('selftext')))\n\nfrom pyspark.sql.functions import udf, lit, array\nfrom pyspark.sql.types import BooleanType\n\n# Define the UDF to check the existence of key words\ndef keyword_present(text, keywords):\n    if text:\n        return any(keyword in text for keyword in keywords)\n    return False\n\nkeyword_udf = udf(keyword_present, BooleanType())\n\n# Apply the UDF\nfor team, keywords in team_keywords.items():\n    submissions = submissions.withColumn(\n        team,\n        keyword_udf(col(\"title\"), array([lit(k) for k in keywords])) | keyword_udf(col(\"selftext\"), array([lit(k) for k in keywords]))\n    )\n    comments = comments.withColumn(\n        team, \n        keyword_udf(col(\"body\"), array([lit(k) for k in keywords]))\n    )\n\nfrom pyspark.sql.functions import sum as sql_sum\n\n# Aggregate the counts for submissions\nsubmissions_counts = submissions.select([sql_sum(col(team).cast(\"int\")).alias(team) for team in team_keywords.keys()])\n\n# Aggregate the counts for comments\ncomments_counts = comments.select([sql_sum(col(team).cast(\"int\")).alias(team) for team in team_keywords.keys()])\n\n# Convert the Spark DataFrame to a Pandas DataFrame\nsubmissions_counts_pd = submissions_counts.toPandas()\ncomments_counts_pd = comments_counts.toPandas()\n\n# Transform the DataFrame to a long format\nsubmissions_counts_long = submissions_counts_pd.melt(var_name='Teams', value_name='Mentions')\ncomments_counts_long = comments_counts_pd.melt(var_name='Teams', value_name='Mentions')\n\n\nGoal: Identify the teams that have the most engagement on the main college basketball subreddit.\nTo commence our analysis of the 2022 basketball tournament, it’s crucial to identify key teams for detailed study. Among the 68 participating teams, our focus will be on the Elite 8. These teams, namely Houston, Kansas, Villanova, Duke, Arkansas, Saint Peter’s, North Carolina, and Miami, not only excelled in the tournament but also garnered significant audience interest, as per the 2022 DI Men’s Basketball Championship Official Bracket (https://www.ncaa.com/brackets/basketball-men/d1/2022). Additionally, incorporating insights from author_flair_text analysis, we included Purdue and Illinois, two teams that enjoyed considerable support, to broaden our scope.\n\n\n\n\n\nCode\nimport plotly.express as px\n\n# Create the interactive Histogram for Submissions Counts\nfig1 = px.bar(submissions_counts_long, x='Teams', y='Mentions', title='Histogram of Team Mentions in Submissions')\n\nfig1.update_layout(\n    xaxis_title='Teams',\n    yaxis_title='Mentions',\n    xaxis={'categoryorder':'total descending'},\n    title_x=0.5\n)\n\nfig1.show()\n\n\n\nFigure 15: The total number of mentions in the submissions dataframe for some of the best teams during the 2021-2022 college basketball season\n\n\nThe graph presents a striking observation: Miami is mentioned markedly more often than other teams, a notably unexpected finding. Additionally, it reveals that the comment mention counts for Kansas, the 2022 champion, North Carolina, the runner-up, and the consistently strong Purdue, significantly exceed those of other teams. This aligns with typical expectations and highlights their prominence in discussions.\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: The total number of mentions in the comments dataframe for some of the best teams during the 2021-2022 college basketball season\n\n\nThe data from the comment counts largely mirrors the trends observed in the previous figure, with a notable exception: Purdue’s mentions significantly surpass those of Kansas and North Carolina, aligning them more closely with Miami’s high mention frequency. This suggests a distinct level of engagement and interest in Purdue, setting it apart from the other teams.\nThe empirical analysis reveals a correlation between a team’s number of mentions and factors like popularity and season performance. Frequently mentioned teams include top performers like Kansas, the eventual champions, and unexpected contenders like North Carolina, which aligns with our initial expectations. Intriguingly, a team like Miami, despite a lower seed ranking and only reaching the top eight, has garnered more submissions and comment mentions than even the championship team. This anomaly suggests there are additional underlying factors influencing Miami’s high visibility, warranting further investigation to uncover these reasons.\nAs we progress, our objective is to conduct a detailed analysis of the daily mention trends for each team. This will offer a more nuanced understanding of how audience engagement evolved over the course of the tournament. To optimize our analysis, and informed by our previous findings, we’ve narrowed our focus to Miami, Kansas, North Carolina, and Purdue. These four teams, having attracted a significantly higher volume of mentions, are ideal candidates for our in-depth examination of engagement patterns.\n\n\n\n\n\n\n\n\n\n\n\nFigure 17: The daily number of mentions in the submissions dataframe for 4 of the best teams during the 2021-2022 college basketball season\n\n\nThe chart illustrates a distinct trend: From the season’s onset in November 2021 to March 2022, Miami led in commit frequency, surpassing other teams. However, a shift occurred in mid-March 2022, as Miami’s commit frequency began to decline, eventually aligning with the baseline levels seen in other teams. Concurrently, there was a notable surge in submissions related to Kansas and North Carolina, culminating in a peak in early April 2022. This increase is clearly linked to their progression to the finals, reflecting heightened audience interest and engagement as these teams advanced in the tournament.\n\n\n\n\n\n\n\n\n\n\n\nFigure 18: The daily number of mentions in the comments dataframe for 4 of the best teams during the 2021-2022 college basketball season\n\n\nThe data shows that while Miami and Purdue have a higher volume of daily comments, the disparity isn’t as marked when compared to other teams. Both teams experienced a peak in comment activity from mid-to-late March. This trend aligns with key tournament events: Purdue’s journey ended in the top 16 after their loss to St. Peter’s on March 25, while Miami concluded in the top 8 following their defeat by Kansas on March 27. North Carolina’s peak in comment volume around mid-March can be directly attributed to their victory over the previous year’s champions, Baylor. Kansas, on the other hand, saw its comment numbers reach the highest point among all teams in early April 2022, a testament to their ultimate championship victory, drawing substantial audience engagement and discussion.\nOverall, the variations in comment volume mirror the dynamics of audience engagement. As the season approaches its climax, particularly the finals, discussions intensify. The disparity in comment counts across different teams highlights the variations in their popularity and performance throughout the season. The data vividly illustrates that audience engagement peaked during critical matches, with this fervor culminating in the finals on April 4, indicating a high level of interest and involvement from fans during these pivotal moments of the tournament."
  }
]